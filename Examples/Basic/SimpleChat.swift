//
//  SimpleChat.swift
//  SwiftResponsesDSL Examples
//
//  Basic example showing the simplest way to use SwiftResponsesDSL
//  for a single chat interaction.
//
//  Generated by AI-assisted code generation.
//  Created by Richard Naszcyniec on [Date].
//  Copyright © [Year] Richard Naszcyniec. All rights reserved.
//

import SwiftResponsesDSL

/// Example 1: Simplest Chat Interaction
/// This shows the absolute minimum code needed to chat with an LLM
func simpleChatExample() async throws {
    print("🚀 Starting Simple Chat Example")
    print("=================================")

    // 1. Create a client with your API endpoint
    let client = try LLMClient(baseURLString: "https://api.openai.com/v1/responses")

    // 2. Send a simple message and get a response
    let response = try await client.chat(model: "gpt-4", message: "Hello, how are you?")

    // 3. Print the response
    if let message = response.choices.first?.message.content {
        print("🤖 Assistant:", message)
    } else {
        print("🤖 Assistant: (No response)")
    }

    print("✅ Simple chat completed!")
}

/// Example 2: Using Different Models
/// Shows how to easily switch between different LLM models
func differentModelsExample() async throws {
    print("\n🔄 Different Models Example")
    print("============================")

    let client = try LLMClient(baseURLString: "https://api.openai.com/v1/responses")

    let models = ["gpt-4", "gpt-3.5-turbo", "claude-3-sonnet"]

    for model in models {
        print("📝 Trying model: \(model)")
        let response = try await client.chat(model: model, message: "Say hello in one word")
        if let message = response.choices.first?.message.content {
            print("   🤖 \(model):", message)
        }
        print()
    }

    print("✅ Model comparison completed!")
}

/// Example 3: Basic Error Handling
/// Shows how to handle common errors gracefully
func errorHandlingExample() async {
    print("\n🛡️  Error Handling Example")
    print("==========================")

    do {
        // Try with an invalid URL
        let client = try LLMClient(baseURLString: "https://invalid-url.com")
        let response = try await client.chat(model: "gpt-4", message: "Hello")
        print("🤖 Response:", response.choices.first?.message.content ?? "None")

    } catch LLMError.invalidURL {
        print("❌ Error: Invalid URL provided")
    } catch LLMError.networkError(let message) {
        print("❌ Network Error:", message)
    } catch {
        print("❌ Unexpected Error:", error.localizedDescription)
    }

    print("✅ Error handling demonstrated!")
}

/// Example 4: Multiple Messages
/// Shows how to send multiple messages in a single conversation
func multipleMessagesExample() async throws {
    print("\n💬 Multiple Messages Example")
    print("============================")

    let client = try LLMClient(baseURLString: "https://api.openai.com/v1/responses")

    // Send multiple messages as an array
    let messages: [any ResponseMessage] = [
        SystemMessage(text: "You are a helpful assistant"),
        UserMessage(text: "What's the capital of France?"),
        AssistantMessage(text: "The capital of France is Paris."),
        UserMessage(text: "What's its population?")
    ]

    let request = try ResponseRequest(
        model: "gpt-4",
        input: messages
    )

    let response = try await client.respond(to: request)

    if let content = response.choices.first?.message.content {
        print("🤖 Assistant:", content)
    }

    print("✅ Multiple messages completed!")
}

/// Main function to run all basic examples
func runBasicExamples() async {
    print("🎯 SwiftResponsesDSL - Basic Examples")
    print("=====================================")
    print("This set of examples shows the fundamental usage patterns.")
    print("Each example builds on the previous one, introducing new concepts.\n")

    do {
        try await simpleChatExample()
        try await differentModelsExample()
        await errorHandlingExample()
        try await multipleMessagesExample()

        print("\n🎉 All basic examples completed successfully!")
        print("💡 Next: Try the Intermediate examples to learn advanced features!")

    } catch {
        print("❌ Example failed with error:", error.localizedDescription)
    }
}
