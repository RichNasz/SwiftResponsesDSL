//
//  WhatIsDSL.swift
//  SwiftResponsesDSL Examples
//
//  Introduction to Domain-Specific Languages (DSLs) and why they matter
//  for API interactions and developer experience.
//
//  Generated by AI-assisted code generation.
//  Created by Richard Naszcyniec on [Date].
//  Copyright ¬© [Year] Richard Naszcyniec. All rights reserved.
//

/// Example 1: Traditional API vs DSL Approach
/// Shows the difference between imperative API calls and declarative DSL syntax
func traditionalVsDSLExample() async throws {
    print("üîÑ Traditional API vs DSL")
    print("========================")

    let client = try LLMClient(baseURLString: "https://api.openai.com/v1/responses")

    print("üìù Traditional Approach (Imperative):")
    print("   - Manual request construction")
    print("   - Explicit parameter setting")
    print("   - Verbose and repetitive")
    print("   - Error-prone")

    // Traditional approach - lots of boilerplate
    let traditionalRequest = try ResponseRequest(
        model: "gpt-4",
        config: [
            Temperature(0.7),
            MaxOutputTokens(150),
            TopP(0.9),
            FrequencyPenalty(0.1)
        ],
        input: [
            SystemMessage(text: "You are a helpful assistant"),
            UserMessage(text: "Explain recursion with an example")
        ]
    )

    print("   ü§ñ Traditional request created with \(traditionalRequest.input.count) messages")

    print("\nüéØ DSL Approach (Declarative):")
    print("   - Natural, readable syntax")
    print("   - Compile-time validation")
    print("   - Less boilerplate")
    print("   - Type-safe")

    // DSL approach - clean and readable
    let dslRequest = try ResponseRequest(
        model: "gpt-4",
        config: {
            Temperature(0.7)
            MaxOutputTokens(150)
            TopP(0.9)
            FrequencyPenalty(0.1)
        },
        input: {
            system("You are a helpful assistant")
            user("Explain recursion with an example")
        }
    )

    print("   ü§ñ DSL request created - same result, cleaner code")

    // Both produce the same API call, but DSL is much more readable
    let traditionalResponse = try await client.respond(to: traditionalRequest)
    let dslResponse = try await client.respond(to: dslRequest)

    print("\nüìä Comparison:")
    print("   ‚Ä¢ Traditional: \(traditionalRequest.input.count) messages, \(traditionalRequest.config?.count ?? 0) parameters")
    print("   ‚Ä¢ DSL: Same functionality, more readable")
    print("   ‚Ä¢ Winner: DSL for maintainability and developer experience!")

    print("‚úÖ DSL vs Traditional comparison completed!")
}

/// Example 2: DSL Benefits Demonstration
/// Shows the concrete benefits of using DSLs
func dslBenefitsExample() async throws {
    print("\nüí° DSL Benefits Demonstration")
    print("============================")

    let client = try LLMClient(baseURLString: "https://api.openai.com/v1/responses")

    print("üéØ Benefit 1: Readability")
    print("   Code reads like natural language:")

    let readableRequest = try ResponseRequest(
        model: "gpt-4",
        config: {
            Temperature(0.8)        // Creative but focused
            MaxOutputTokens(100)    // Keep responses concise
        },
        input: {
            system("You are a coding tutor")
            user("How do I implement a binary search in Swift?")
        }
    )

    print("   ‚úÖ This reads like: 'Using GPT-4 with 80% temperature and 100 max tokens,")
    print("      ask the coding tutor how to implement binary search in Swift'")

    print("\nüéØ Benefit 2: Type Safety")
    print("   Compile-time validation prevents runtime errors:")

    do {
        // This will compile successfully
        let validRequest = try ResponseRequest(
            model: "gpt-4",
            config: {
                Temperature(0.7)      // Valid: 0.0 to 2.0
            },
            input: {
                user("Hello")
            }
        )
        print("   ‚úÖ Valid temperature accepted")

    } catch LLMError.invalidValue(let message) {
        print("   ‚ùå This shouldn't happen: \(message)")
    }

    print("\nüéØ Benefit 3: IDE Support")
    print("   Auto-completion and syntax highlighting:")

    // In a real IDE, you'd get:
    // - Auto-completion for Temperature, MaxOutputTokens, etc.
    // - Syntax highlighting for the DSL blocks
    // - Quick help documentation for each parameter
    let ideFriendlyRequest = try ResponseRequest(
        model: "gpt-4",
        config: {
            // IDE shows available parameters here
            Temperature(0.7)
            // IDE shows valid range and documentation
        },
        input: {
            // IDE shows available message types
            system("Context")
            user("Question")
            // IDE helps with syntax
        }
    )

    print("   ‚úÖ IDE provides full support for DSL syntax")

    print("\nüéØ Benefit 4: Composability")
    print("   Easy to combine and reuse components:")

    // Create reusable configuration blocks
    func creativeConfig() -> [any ResponseConfigParameter] {
        [
            Temperature(0.9),
            TopP(0.9),
            MaxOutputTokens(200)
        ]
    }

    func educationalContext() -> [any ResponseMessage] {
        [
            SystemMessage(text: "You are an expert educator who explains complex topics simply")
        ]
    }

    // Compose them together
    let composedRequest = try ResponseRequest(
        model: "gpt-4",
        config: creativeConfig(),  // Reusable config
        input: educationalContext() + [  // Composed context
            UserMessage(text: "Explain quantum computing")
        ]
    )

    print("   ‚úÖ Components composed easily for reuse")

    let response = try await client.respond(to: composedRequest)
    if let explanation = response.choices.first?.message.content {
        print("   ü§ñ Response: \(explanation.prefix(100))...")
    }

    print("‚úÖ DSL benefits demonstrated!")
}

/// Example 3: DSL Evolution and Maintenance
/// Shows how DSLs make code evolution easier
func dslEvolutionExample() async throws {
    print("\nüîÑ DSL Evolution & Maintenance")
    print("=============================")

    let client = try LLMClient(baseURLString: "https://api.openai.com/v1/responses")

    print("üìà Version 1: Simple chat")

    let v1Request = try ResponseRequest(
        model: "gpt-3.5-turbo",
        input: {
            user("Hello")
        }
    )

    print("   Simple, but limited functionality")

    print("\nüìà Version 2: Add configuration")

    let v2Request = try ResponseRequest(
        model: "gpt-4",
        config: {
            Temperature(0.7)
        },
        input: {
            system("You are helpful")
            user("Hello")
        }
    )

    print("   Added temperature and system message - DSL makes this easy")

    print("\nüìà Version 3: Advanced features")

    let v3Request = try ResponseRequest(
        model: "gpt-4",
        config: {
            Temperature(0.7)
            MaxOutputTokens(100)
            TopP(0.9)
            StreamOptions(["include_usage": true])
        },
        input: {
            system("You are a helpful assistant")
            user("Explain recursion")
        }
    )

    print("   Added streaming, token limits, and advanced parameters")
    print("   DSL syntax stays clean regardless of complexity")

    print("\nüéØ Maintenance Benefits:")
    print("   ‚Ä¢ Easy to add/remove parameters")
    print("   ‚Ä¢ Clear intent in code")
    print("   ‚Ä¢ Type safety prevents errors")
    print("   ‚Ä¢ IDE support for refactoring")

    // Demonstrate that all versions work
    for (version, request) in [("V1", v1Request), ("V2", v2Request), ("V3", v3Request)] {
        let response = try await client.respond(to: request)
        if let content = response.choices.first?.message.content {
            print("   \(version): \(content.prefix(50))...")
        }
    }

    print("‚úÖ DSL evolution demonstrated!")
}

/// Example 4: DSL Anti-Patterns and Best Practices
/// Shows common mistakes and how to avoid them
func dslPatternsExample() async {
    print("\nüö´ DSL Anti-Patterns & Best Practices")
    print("====================================")

    print("‚ùå Anti-Pattern 1: Over-complication")

    // Bad: Trying to do too much in one request
    do {
        let badRequest = try ResponseRequest(
            model: "gpt-4",
            config: {
                Temperature(0.1)  // Too restrictive
                MaxOutputTokens(10)  // Too limited
                // Too many conflicting parameters
                TopP(0.1)
                FrequencyPenalty(2.0)
                PresencePenalty(2.0)
            },
            input: {
                system("You are everything: a teacher, therapist, chef, mechanic...")
                user("Solve world hunger, explain quantum physics, and tell me a joke")
            }
        )
        print("   This request tries to do too much!")

    } catch {
        print("   ‚ùå Request failed: \(error.localizedDescription)")
    }

    print("\n‚úÖ Best Practice 1: Focused, Single-Responsibility Requests")

    let client = try LLMClient(baseURLString: "https://api.openai.com/v1/responses")

    // Good: Focused request with clear purpose
    let goodRequest = try ResponseRequest(
        model: "gpt-4",
        config: {
            Temperature(0.7)      // Balanced creativity
            MaxOutputTokens(150)  // Reasonable length
        },
        input: {
            system("You are a helpful programming tutor")
            user("Explain how recursion works with a simple example")
        }
    )

    let response = try await client.respond(to: goodRequest)
    if let explanation = response.choices.first?.message.content {
        print("   ‚úÖ Focused request: \(explanation.prefix(100))...")
    }

    print("\n‚ùå Anti-Pattern 2: Ignoring Type Safety")

    // Bad: Not using the DSL's type system
    do {
        // Manual construction instead of DSL
        let manualConfig: [Any] = [
            "temperature", 0.7,  // Not type-safe
            "max_tokens", 100     // String keys, runtime errors
        ]
        print("   Manual construction loses type safety!")

    } catch {
        print("   ‚ùå Manual approach: prone to runtime errors")
    }

    print("\n‚úÖ Best Practice 2: Leverage Type System")

    // Good: Using DSL's compile-time guarantees
    let typeSafeRequest = try ResponseRequest(
        model: "gpt-4",
        config: {
            Temperature(0.7)      // Compile-time validation
            MaxOutputTokens(100)  // Type-safe construction
        },
        input: {
            user("Hello")
        }
    )
    print("   ‚úÖ Type-safe: Compiler catches errors before runtime")

    print("\nüéØ Key Takeaways:")
    print("   ‚Ä¢ Keep requests focused and single-purpose")
    print("   ‚Ä¢ Use DSL's type system for safety")
    print("   ‚Ä¢ Prefer composition over monolithic requests")
    print("   ‚Ä¢ Test parameters to find optimal values")

    print("‚úÖ DSL patterns and best practices demonstrated!")
}

/// Main function to run all DSL learning examples
func runDSLLearningExamples() async {
    print("üìö SwiftResponsesDSL - DSL Learning")
    print("===================================")
    print("Understanding Domain-Specific Languages and their benefits.\n")

    do {
        try await traditionalVsDSLExample()
        try await dslBenefitsExample()
        try await dslEvolutionExample()
        await dslPatternsExample()

        print("\nüéâ DSL learning completed!")
        print("üí° DSLs make complex APIs simple and maintainable!")
        print("üìñ Next: Explore practical examples in other folders!")

    } catch {
        print("‚ùå Example failed with error:", error.localizedDescription)
    }
}
