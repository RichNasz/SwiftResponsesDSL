//
//  main.swift
//  AIChatApp
//
//  Sample application demonstrating SwiftResponsesDSL integration
//  in a real-world command-line chat application.
//
//  Generated by AI-assisted code generation.
//  Created by Richard Naszcyniec on [Date].
//  Copyright ¬© [Year] Richard Naszcyniec. All rights reserved.
//

import SwiftResponsesDSL
import Foundation

// MARK: - Application Configuration

/// Application configuration and settings
struct AppConfig {
    let apiKey: String
    let baseURL: String
    let defaultModel: String
    let maxConversationLength: Int

    static func load() -> AppConfig {
        AppConfig(
            apiKey: ProcessInfo.processInfo.environment["OPENAI_API_KEY"] ?? "",
            baseURL: "https://api.openai.com/v1/responses",
            defaultModel: "gpt-4",
            maxConversationLength: 50
        )
    }
}

// MARK: - Chat Service

/// Service responsible for handling AI chat interactions
class ChatService {
    private let client: LLMClient
    private let config: AppConfig
    private var conversation = ResponseConversation()

    init(config: AppConfig) throws {
        self.config = config
        self.client = try LLMClient(baseURLString: config.baseURL)

        // Initialize with system prompt
        setupSystemPrompt()
    }

    private func setupSystemPrompt() {
        conversation.append(system: """
        You are a helpful AI assistant integrated into a command-line chat application.
        Keep your responses concise but informative. If asked about your capabilities,
        mention that you're powered by SwiftResponsesDSL. Be friendly and engaging.
        """)
    }

    func sendMessage(_ message: String, streaming: Bool = false) async throws -> String {
        // Add user message to conversation
        conversation.append(user: message)

        // Manage conversation length
        trimConversationIfNeeded()

        if streaming {
            return try await sendStreamingMessage()
        } else {
            return try await sendRegularMessage()
        }
    }

    private func sendRegularMessage() async throws -> String {
        let request = try ResponseRequest(
            model: config.defaultModel,
            config: {
                Temperature(0.7)
                MaxOutputTokens(500)
            },
            input: conversation.messages
        )

        let response = try await client.respond(to: request)
        conversation.append(response: response)

        return response.choices.first?.message.content ?? "No response received"
    }

    private func sendStreamingMessage() async throws -> String {
        let request = try ResponseRequest(
            model: config.defaultModel,
            config: {
                Temperature(0.7)
                MaxOutputTokens(500)
                StreamOptions(["include_usage": true])
            },
            input: conversation.messages
        )

        let stream = client.stream(request: request)
        var fullResponse = ""
        var isFirstChunk = true

        for try await event in stream {
            switch event {
            case .outputItemAdded(let item):
                if case .message(let message) = item,
                   let content = message.content {
                    if isFirstChunk {
                        print("ü§ñ ", terminator: "")
                        isFirstChunk = false
                    }
                    print(content, terminator: "")
                    fflush(stdout)
                    fullResponse += content
                }

            case .completed(let response):
                conversation.append(response: response)
                print("\n")

            case .created:
                print("üí≠ Thinking...", terminator: "")

            default:
                break
            }
        }

        return fullResponse
    }

    private func trimConversationIfNeeded() {
        // Keep system message and last N exchanges
        if conversation.messages.count > config.maxConversationLength {
            let systemMessage = conversation.messages.first!
            let recentMessages = conversation.messages.suffix(config.maxConversationLength - 1)
            conversation = ResponseConversation()
            conversation.append(message: systemMessage)
            recentMessages.forEach { conversation.append(message: $0) }
        }
    }

    func clearConversation() {
        conversation = ResponseConversation()
        setupSystemPrompt()
    }

    func getConversationSummary() -> String {
        let messageCount = conversation.messages.count
        let userMessages = conversation.messages.filter { $0.role == .user }.count
        let assistantMessages = conversation.messages.filter { $0.role == .assistant }.count

        return """
        Conversation Summary:
        ‚Ä¢ Total messages: \(messageCount)
        ‚Ä¢ User messages: \(userMessages)
        ‚Ä¢ Assistant messages: \(assistantMessages)
        ‚Ä¢ Max conversation length: \(config.maxConversationLength)
        """
    }
}

// MARK: - Command Line Interface

/// Simple command-line interface for the chat application
class CLI {
    private let chatService: ChatService
    private let config: AppConfig

    init(chatService: ChatService, config: AppConfig) {
        self.chatService = chatService
        self.config = config
    }

    func run() async {
        print("ü§ñ AI Chat App powered by SwiftResponsesDSL")
        print("==========================================")
        print("Commands:")
        print("  /help    - Show this help")
        print("  /clear   - Clear conversation history")
        print("  /summary - Show conversation summary")
        print("  /stream  - Toggle streaming mode")
        print("  /quit    - Exit the application")
        print()

        var streamingMode = false

        while true {
            print("üë§ You: ", terminator: "")
            guard let input = readLine()?.trimmingCharacters(in: .whitespacesAndNewlines),
                  !input.isEmpty else {
                continue
            }

            switch input.lowercased() {
            case "/quit", "/q":
                print("üëã Goodbye!")
                return

            case "/help", "/h":
                showHelp()

            case "/clear", "/c":
                chatService.clearConversation()
                print("üßπ Conversation cleared!")

            case "/summary", "/s":
                print(chatService.getConversationSummary())

            case "/stream", "/st":
                streamingMode.toggle()
                print("üåä Streaming mode: \(streamingMode ? "ON" : "OFF")")

            default:
                do {
                    let startTime = Date()
                    let response = try await chatService.sendMessage(input, streaming: streamingMode)
                    let responseTime = Date().timeIntervalSince(startTime)

                    if !streamingMode {
                        print("ü§ñ Assistant: \(response)")
                    }

                    print("‚è±Ô∏è  Response time: \(String(format: "%.2f", responseTime))s")

                } catch LLMError.networkError(let message) {
                    print("‚ùå Network Error: \(message)")
                    print("üí° Check your internet connection and API key")
                } catch LLMError.invalidValue(let message) {
                    print("‚ùå Configuration Error: \(message)")
                } catch {
                    print("‚ùå Unexpected Error: \(error.localizedDescription)")
                }
            }

            print() // Empty line for readability
        }
    }

    private func showHelp() {
        print("""
        ü§ñ AI Chat App Help
        ===================

        This is a sample application demonstrating SwiftResponsesDSL integration.

        Features:
        ‚Ä¢ Natural language conversation with AI
        ‚Ä¢ Streaming and regular response modes
        ‚Ä¢ Conversation history management
        ‚Ä¢ Error handling and recovery

        Commands:
        ‚Ä¢ /help, /h    - Show this help message
        ‚Ä¢ /clear, /c   - Clear conversation history
        ‚Ä¢ /summary, /s - Show conversation statistics
        ‚Ä¢ /stream, /st - Toggle streaming mode on/off
        ‚Ä¢ /quit, /q    - Exit the application

        Tips:
        ‚Ä¢ Try asking about programming, science, or creative writing
        ‚Ä¢ Use streaming mode for real-time responses
        ‚Ä¢ The AI remembers your conversation context
        ‚Ä¢ Type naturally - no special formatting needed

        Powered by SwiftResponsesDSL üöÄ
        """)
    }
}

// MARK: - Application Entry Point

@main
struct AIChatApp {
    static func main() async {
        do {
            // Load configuration
            let config = AppConfig.load()

            // Validate API key
            guard !config.apiKey.isEmpty else {
                print("‚ùå Error: OPENAI_API_KEY environment variable not set")
                print("üí° Set your API key: export OPENAI_API_KEY='your-key-here'")
                return
            }

            // Initialize services
            let chatService = try ChatService(config: config)
            let cli = CLI(chatService: chatService, config: config)

            // Run the application
            await cli.run()

        } catch LLMError.invalidURL {
            print("‚ùå Error: Invalid API endpoint URL")
        } catch {
            print("‚ùå Failed to start application: \(error.localizedDescription)")
        }
    }
}
