//
//  SwiftResponsesDSL.swift
//  SwiftResponsesDSL
//
//  Main entry point for the SwiftResponsesDSL package
//  Provides unified access to all DSL components
//
//  Generated by AI-assisted code generation.
//  Created by Richard Naszcyniec on [Date].
//  Copyright © [Year] Richard Naszcyniec. All rights reserved.
//
//  === MODULARIZED ARCHITECTURE ===
//  This file serves as the main entry point for the SwiftResponsesDSL package.
//  The implementation has been modularized into separate files for better
//  maintainability and readability:
//
//  - Core.swift: Basic enums, protocols, and AnyCodable
//  - Messages.swift: Message types and content parts
//  - Configuration.swift: Configuration parameter structs
//  - API.swift: Request/response types and tools
//  - Client.swift: LLMClient actor and networking
//  - Builders.swift: Result builders for declarative syntax
//  - Convenience.swift: Helper functions
//
//  This approach provides:
//  ✅ Better code organization and navigation
//  ✅ Easier maintenance and debugging
//  ✅ Clear separation of concerns
//  ✅ Improved developer experience
//

import Foundation

// MARK: - Package Overview

/// SwiftResponsesDSL is an embedded Swift Domain-Specific Language (DSL) designed
/// to simplify communication with Large Language Model (LLM) inference servers
/// that support OpenAI-compatible Responses endpoints.
///
/// Key Features:
/// - Type-safe API interactions with compile-time validation
/// - Declarative syntax using Swift's result builder pattern
/// - Multimodal content support (text, images, files)
/// - Tool integration (functions, file search, web search)
/// - Conversation history management
/// - Both synchronous and streaming response handling
/// - Comprehensive error handling with localized messages
/// - Modular architecture for maintainability and extensibility
///
/// ## Example Usage
///
/// ### Basic Chat Interaction
/// ```swift
/// let client = try LLMClient(baseURLString: "https://api.openai.com/v1/responses")
///
/// // Simple synchronous chat
/// let response = try await client.chat(model: "gpt-4", message: "Hello!")
/// print(response.choices.first?.message.content ?? "No response")
/// ```
///
/// ### Advanced Configuration with Result Builders
/// ```swift
/// // Create a request with advanced configuration
/// let request = try ResponseRequest(
///     model: "gpt-4",
///     config: {
///         Temperature(0.7)    // Control randomness
///         MaxOutputTokens(100) // Limit response length
///         TopP(0.9)          // Nucleus sampling
///         FrequencyPenalty(0.1) // Reduce repetition
///     },
///     input: {
///         system("You are a helpful AI assistant specialized in programming.")
///         user("Explain how to implement a binary search algorithm in Swift.")
///     }
/// )
///
/// let response = try await client.respond(to: request)
/// ```
///
/// ### Streaming Responses
/// ```swift
/// // Handle streaming responses for real-time interaction
/// let stream = client.stream(request: request)
///
/// for try await event in stream {
///     switch event {
///     case .created:
///         print("Stream created")
///     case .inProgress:
///         print("Processing...")
///     case .completed(let response):
///         print("Final response:", response.choices.first?.message.content ?? "")
///     case .outputItemAdded(let item):
///         if case .message(let message) = item {
///             print("New content:", message.content)
///         }
///     case .unknown(let type, _):
///         print("Unknown event type:", type)
///     }
/// }
/// ```
///
/// ### Conversation Management
/// ```swift
/// // Manage conversation history
/// var conversation = ResponseConversation()
///
/// conversation.append(system: "You are a helpful programming tutor.")
/// conversation.append(user: "What is recursion?")
///
/// let response = try await client.chat(conversation: conversation)
/// conversation.append(response: response)
///
/// // Continue the conversation
/// conversation.append(user: "Can you give me an example?")
/// let followUp = try await client.chat(conversation: conversation)
/// ```
///
/// The DSL supports both imperative and declarative programming styles,
/// making it suitable for simple interactions and complex workflows alike.

// MARK: - Module Information

/// This file serves as the main entry point for the SwiftResponsesDSL package.
/// The implementation has been modularized into separate files for better
/// maintainability and readability:
///
/// - Core.swift: Basic enums, protocols, and AnyCodable
/// - Messages.swift: Message types and content parts
/// - Configuration.swift: Configuration parameter structs
/// - API.swift: Request/response types and tools
/// - Client.swift: LLMClient actor and networking
/// - Builders.swift: Result builders for declarative syntax
/// - Convenience.swift: Helper functions
///
/// All types and functions are automatically available through this main module.
