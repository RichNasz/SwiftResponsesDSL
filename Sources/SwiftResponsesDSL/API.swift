//
//  API.swift
//  SwiftResponsesDSL
//
//  Request/Response types and tools for the SwiftResponsesDSL
//
//  Generated by AI-assisted code generation.
//  Created by Richard Naszcyniec on [Date].
//  Copyright Â© [Year] Richard Naszcyniec. All rights reserved.
//

import Foundation

// MARK: - Tool Definitions

/// Defines tools (e.g., function, file_search, web_search_preview) with configurations
public struct Tool: Codable, Sendable {
    public let type: String
    public let function: Function?
    public let fileSearch: FileSearch?
    public let webSearchPreview: WebSearchPreview?

    public enum CodingKeys: String, CodingKey {
        case type, function
        case fileSearch = "file_search"
        case webSearchPreview = "web_search_preview"
    }

    public struct Function: Codable, Sendable {
        public let name: String
        public let description: String?
        public let parameters: [String: AnyCodable]?
        public let strict: Bool?

        public enum CodingKeys: String, CodingKey {
            case name, description, parameters, strict
        }
    }

    public struct FileSearch: Codable, Sendable {
        public let filters: [String: AnyCodable]?
        public let maxNumResults: Int?
        public let rankingOptions: RankingOptions?
        public let vectorStoreIds: [String]?

        public enum CodingKeys: String, CodingKey {
            case filters
            case maxNumResults = "max_num_results"
            case rankingOptions = "ranking_options"
            case vectorStoreIds = "vector_store_ids"
        }

        public struct RankingOptions: Codable, Sendable {
            public let ranker: String
            public let scoreThreshold: Double

            public enum CodingKeys: String, CodingKey {
                case ranker
                case scoreThreshold = "score_threshold"
            }
        }
    }

    public struct WebSearchPreview: Codable, Sendable {
        public let domains: [String]
        public let searchContextSize: String
        public let userLocation: UserLocation?

        public enum CodingKeys: String, CodingKey {
            case domains
            case searchContextSize = "search_context_size"
            case userLocation = "user_location"
        }

        public struct UserLocation: Codable, Sendable {
            public let type: String
            public let city: String?
            public let country: String?
            public let region: String?
            public let timezone: String?

            public enum CodingKeys: String, CodingKey {
                case type, city, country, region, timezone
            }
        }
    }
}

// MARK: - Output Items

/// Represents different types of output items in responses
public enum OutputItem: Decodable, Sendable {
    case message(AssistantMessage)
    case toolCall(FunctionCall)
    case fileSearchCall(FileSearchCall)
    case webSearchCall(WebSearchCall)

    private enum CodingKeys: String, CodingKey {
        case type
    }

    private enum ItemKeys: String, CodingKey {
        case message, toolCall = "tool_call", fileSearchCall = "file_search_call", webSearchCall = "web_search_call"
    }

    public init(from decoder: Decoder) throws {
        let container = try decoder.container(keyedBy: CodingKeys.self)
        let type = try container.decode(String.self, forKey: .type)

        switch type {
        case "message":
            let itemContainer = try decoder.container(keyedBy: ItemKeys.self)
            let message = try itemContainer.decode(AssistantMessage.self, forKey: .message)
            self = .message(message)
        case "tool_call":
            let itemContainer = try decoder.container(keyedBy: ItemKeys.self)
            let toolCall = try itemContainer.decode(FunctionCall.self, forKey: .toolCall)
            self = .toolCall(toolCall)
        case "file_search_call":
            let itemContainer = try decoder.container(keyedBy: ItemKeys.self)
            let fileSearchCall = try itemContainer.decode(FileSearchCall.self, forKey: .fileSearchCall)
            self = .fileSearchCall(fileSearchCall)
        case "web_search_call":
            let itemContainer = try decoder.container(keyedBy: ItemKeys.self)
            let webSearchCall = try itemContainer.decode(WebSearchCall.self, forKey: .webSearchCall)
            self = .webSearchCall(webSearchCall)
        default:
            throw DecodingError.dataCorruptedError(forKey: .type, in: container, debugDescription: "Unknown output item type: \(type)")
        }
    }

    /// Function call output item
    public struct FunctionCall: Decodable, Sendable {
        public let id: String
        public let function: Function

        public enum CodingKeys: String, CodingKey {
            case id, function
        }

        public struct Function: Decodable, Sendable {
            public let name: String
            public let arguments: String
        }
    }

    /// File search call output item
    public struct FileSearchCall: Decodable, Sendable {
        public let id: String
        public let queries: [String]

        public enum CodingKeys: String, CodingKey {
            case id, queries
        }
    }

    /// Web search call output item
    public struct WebSearchCall: Decodable, Sendable {
        public let id: String
        public let searchQuery: String

        public enum CodingKeys: String, CodingKey {
            case id
            case searchQuery = "search_query"
        }
    }
}

// MARK: - Streaming Events

/// Represents events in a streaming response
public enum ResponseEvent: Sendable {
    case created
    case inProgress
    case completed(Response)
    case outputItemAdded(OutputItem)
    case unknown(String, [String: AnyCodable])
}

// MARK: - Response Types

/// Represents a response from the LLM API
public struct Response: Decodable, Sendable {
    public let id: String
    public let object: String
    public let created: Int
    public let model: String
    public let choices: [Choice]
    public let usage: Usage?
    public let systemFingerprint: String?
    public let serviceTier: String?

    public enum CodingKeys: String, CodingKey {
        case id, object, created, model, choices, usage
        case systemFingerprint = "system_fingerprint"
        case serviceTier = "service_tier"
    }

    /// A choice in the response
    public struct Choice: Decodable, Sendable {
        public let index: Int
        public let message: AssistantMessage?
        public let finishReason: String?
        public let logprobs: Logprobs?

        public enum CodingKeys: String, CodingKey {
            case index, message
            case finishReason = "finish_reason"
            case logprobs
        }

        /// Log probability information
        public struct Logprobs: Decodable, Sendable {
            public let content: [ContentLogprob]?
        }

        /// Log probability for content tokens
        public struct ContentLogprob: Decodable, Sendable {
            public let token: String
            public let logprob: Double
            public let bytes: [Int]?
            public let topLogprobs: [TopLogprob]?

            public enum CodingKeys: String, CodingKey {
                case token, logprob, bytes
                case topLogprobs = "top_logprobs"
            }

            public struct TopLogprob: Decodable, Sendable {
                public let token: String
                public let logprob: Double
                public let bytes: [Int]?
            }
        }
    }

    /// Token usage information
    public struct Usage: Decodable, Sendable {
        public let promptTokens: Int
        public let completionTokens: Int?
        public let totalTokens: Int
        public let completionTokensDetails: CompletionTokensDetails?
        public let promptTokensDetails: PromptTokensDetails?

        public enum CodingKeys: String, CodingKey {
            case promptTokens = "prompt_tokens"
            case completionTokens = "completion_tokens"
            case totalTokens = "total_tokens"
            case completionTokensDetails = "completion_tokens_details"
            case promptTokensDetails = "prompt_tokens_details"
        }

        public struct CompletionTokensDetails: Decodable, Sendable {
            public let reasoningTokens: Int?
            public let acceptedPredictionTokens: Int?
            public let rejectedPredictionTokens: Int?

            public enum CodingKeys: String, CodingKey {
                case reasoningTokens = "reasoning_tokens"
                case acceptedPredictionTokens = "accepted_prediction_tokens"
                case rejectedPredictionTokens = "rejected_prediction_tokens"
            }
        }

        public struct PromptTokensDetails: Decodable, Sendable {
            public let cachedTokens: Int?

            public enum CodingKeys: String, CodingKey {
                case cachedTokens = "cached_tokens"
            }
        }
    }

    // MARK: - Computed Properties

    /// Extracts all assistant messages from the response
    public var assistantMessages: [AssistantMessage] {
        choices.compactMap { $0.message }
    }

    /// Extracts all tool calls from the response
    public var toolCalls: [OutputItem] {
        let calls: [OutputItem] = []
        for choice in choices {
            if let message = choice.message {
                // Extract tool calls from message content
                for contentPart in message.content {
                    if case .text(_) = contentPart {
                        // Parse tool calls from text if present
                        // This would need more sophisticated parsing
                    }
                }
            }
        }
        return calls
    }
}

// MARK: - Request Types

/// Represents a request to the LLM API
public struct ResponseRequest: Encodable, Sendable {
    public var model: String
    public var messages: [any ResponseMessage]
    public var stream: Bool
    public var previousResponseId: String?
    public var temperature: Double?
    public var topP: Double?
    public var maxOutputTokens: Int?
    public var toolChoice: String?
    public var tools: [Tool]?
    public var parallelToolCalls: Bool?
    public var frequencyPenalty: Double?
    public var presencePenalty: Double?
    public var logitBias: [Int: Int]?
    public var user: String?
    public var stop: [String]?
    public var seed: Int?
    public var responseFormat: [String: AnyCodable]?
    public var logprobs: Bool?
    public var topLogprobs: Int?
    public var streamOptions: [String: AnyCodable]?
    public var truncation: String?
    public var store: Bool?
    public var background: Bool?
    public var maxToolCalls: Int?
    public var serviceTier: String?

    public enum CodingKeys: String, CodingKey {
        case model, messages, stream
        case previousResponseId = "previous_response_id"
        case temperature, topP = "top_p"
        case maxOutputTokens = "max_output_tokens"
        case toolChoice = "tool_choice"
        case tools
        case parallelToolCalls = "parallel_tool_calls"
        case frequencyPenalty = "frequency_penalty"
        case presencePenalty = "presence_penalty"
        case logitBias = "logit_bias"
        case user, stop, seed
        case responseFormat = "response_format"
        case logprobs
        case topLogprobs = "top_logprobs"
        case streamOptions = "stream_options"
        case truncation, store, background
        case maxToolCalls = "max_tool_calls"
        case serviceTier = "service_tier"
    }

    public init(model: String, input: [any ResponseMessage], previousResponseId: String? = nil, stream: Bool = false, config: [any ResponseConfigParameter]) throws {
        self.model = model
        self.messages = input
        self.stream = stream
        self.previousResponseId = previousResponseId

        // Initialize all optional properties to nil
        self.temperature = nil
        self.topP = nil
        self.maxOutputTokens = nil
        self.toolChoice = nil
        self.tools = nil
        self.parallelToolCalls = nil
        self.frequencyPenalty = nil
        self.presencePenalty = nil
        self.logitBias = nil
        self.user = nil
        self.stop = nil
        self.seed = nil
        self.responseFormat = nil
        self.logprobs = nil
        self.topLogprobs = nil
        self.streamOptions = nil
        self.truncation = nil
        self.store = nil
        self.background = nil
        self.maxToolCalls = nil
        self.serviceTier = nil

        // Apply configuration parameters
        for param in config {
            try param.apply(to: &self)
        }
    }

    public func encode(to encoder: Encoder) throws {
        var container = encoder.container(keyedBy: CodingKeys.self)

        try container.encode(model, forKey: .model)
        try container.encode(stream, forKey: .stream)

        if let previousResponseId = previousResponseId {
            try container.encode(previousResponseId, forKey: .previousResponseId)
        }

        // Encode messages with type erasure handling
        var messagesContainer = container.nestedUnkeyedContainer(forKey: .messages)
        for message in messages {
            if let systemMessage = message as? SystemMessage {
                try messagesContainer.encode(systemMessage)
            } else if let userMessage = message as? UserMessage {
                try messagesContainer.encode(userMessage)
            } else if let assistantMessage = message as? AssistantMessage {
                try messagesContainer.encode(assistantMessage)
            }
        }

        // Encode optional properties only if they have values
        if let temperature = temperature {
            try container.encode(temperature, forKey: .temperature)
        }
        if let topP = topP {
            try container.encode(topP, forKey: .topP)
        }
        if let maxOutputTokens = maxOutputTokens {
            try container.encode(maxOutputTokens, forKey: .maxOutputTokens)
        }
        if let toolChoice = toolChoice {
            try container.encode(toolChoice, forKey: .toolChoice)
        }
        if let tools = tools {
            try container.encode(tools, forKey: .tools)
        }
        if let parallelToolCalls = parallelToolCalls {
            try container.encode(parallelToolCalls, forKey: .parallelToolCalls)
        }
        if let frequencyPenalty = frequencyPenalty {
            try container.encode(frequencyPenalty, forKey: .frequencyPenalty)
        }
        if let presencePenalty = presencePenalty {
            try container.encode(presencePenalty, forKey: .presencePenalty)
        }
        if let logitBias = logitBias {
            try container.encode(logitBias, forKey: .logitBias)
        }
        if let user = user {
            try container.encode(user, forKey: .user)
        }
        if let stop = stop {
            try container.encode(stop, forKey: .stop)
        }
        if let seed = seed {
            try container.encode(seed, forKey: .seed)
        }
        if let responseFormat = responseFormat {
            try container.encode(responseFormat, forKey: .responseFormat)
        }
        if let logprobs = logprobs {
            try container.encode(logprobs, forKey: .logprobs)
        }
        if let topLogprobs = topLogprobs {
            try container.encode(topLogprobs, forKey: .topLogprobs)
        }
        if let streamOptions = streamOptions {
            try container.encode(streamOptions, forKey: .streamOptions)
        }
        if let truncation = truncation {
            try container.encode(truncation, forKey: .truncation)
        }
        if let store = store {
            try container.encode(store, forKey: .store)
        }
        if let background = background {
            try container.encode(background, forKey: .background)
        }
        if let maxToolCalls = maxToolCalls {
            try container.encode(maxToolCalls, forKey: .maxToolCalls)
        }
        if let serviceTier = serviceTier {
            try container.encode(serviceTier, forKey: .serviceTier)
        }
    }
}

// MARK: - Conversation Management

/// Manages conversation history for multi-turn interactions
public struct ResponseConversation: Sendable {
    public private(set) var messages: [any ResponseMessage]
    public var previousResponseId: String?

    public init(messages: [any ResponseMessage] = []) {
        self.messages = messages
    }

    public mutating func append(_ message: any ResponseMessage) {
        messages.append(message)
    }

    public mutating func append(system text: String) {
        messages.append(SystemMessage(text: text))
    }

    public mutating func append(user text: String) {
        messages.append(UserMessage(text: text))
    }

    public mutating func append(user content: [ContentPart]) {
        messages.append(UserMessage(content: content))
    }

    public mutating func append(assistant text: String) {
        messages.append(AssistantMessage(text: text))
    }

    public mutating func append(assistant content: [ContentPart]) {
        messages.append(AssistantMessage(text: ""))
    }

    public mutating func append(response: Response) {
        // Add assistant message from response
        if let assistantMessage = response.assistantMessages.first {
            messages.append(assistantMessage)
        }

        // Add tool calls if any
        for _ in response.toolCalls {
            // Create a tool message based on the tool call
            // This would need to be implemented based on the specific tool call structure
        }

        // Update previous response ID for server-side state
        previousResponseId = response.id
    }

    public func generateRequest(model: String, stream: Bool = false, config: [any ResponseConfigParameter] = []) throws -> ResponseRequest {
        try ResponseRequest(model: model, input: messages, previousResponseId: previousResponseId, stream: stream, config: config)
    }
}
